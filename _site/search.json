[
  {
    "objectID": "lessons/01_what_is_that.html",
    "href": "lessons/01_what_is_that.html",
    "title": "blog",
    "section": "",
    "text": "import os\n\nos.environ[\"DGLBACKEND\"] = \"pytorch\"\nimport dgl\nimport dgl.data\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n/Users/tu/SourceCode/dirty_data_resolver/env/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n  warnings.warn(\n\n\n\ndataset = dgl.data.CoraGraphDataset()\nprint(f\"Number of categories: {dataset.num_classes}\")\n\nDownloading /Users/tu/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\nExtracting file to /Users/tu/.dgl/cora_v2_d697a464\nFinished data loading and preprocessing.\n  NumNodes: 2708\n  NumEdges: 10556\n  NumFeats: 1433\n  NumClasses: 7\n  NumTrainingSamples: 140\n  NumValidationSamples: 500\n  NumTestSamples: 1000\nDone saving data into cached files.\nNumber of categories: 7\n\n\n\n# A DGL Dataset object may contain one or multiple graphs. The Cora dataset used in this tutorial only consists of one single graph.\ng = dataset[0]\n\n\nprint(\"Node features\")\nprint(g.ndata.keys())\nprint(\"Edge features\")\nprint(g.edata)\n\nNode features\ndict_keys(['train_mask', 'val_mask', 'test_mask', 'label', 'feat'])\nEdge features\n{}\n\n\n\nfrom dgl.nn import GraphConv\n\n\nclass GCN(nn.Module):\n    def __init__(self, in_feats, h_feats, num_classes):\n        super(GCN, self).__init__()\n        self.conv1 = GraphConv(in_feats, h_feats)\n        self.conv2 = GraphConv(h_feats, num_classes)\n\n    def forward(self, g, in_feat):\n        h = self.conv1(g, in_feat)\n        h = F.relu(h)\n        h = self.conv2(g, h)\n        return h\n\n\n\nfrom dgl.data import DGLDataset\n\ndef train(g:DGLDataset, model: GCN):\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n    best_val_acc = 0\n    best_test_acc = 0\n\n    features = g.ndata[\"feat\"]\n    labels = g.ndata[\"label\"]\n    train_mask = g.ndata[\"train_mask\"]\n    val_mask = g.ndata[\"val_mask\"]\n    test_mask = g.ndata[\"test_mask\"]\n    for e in range(100):\n        # Forward\n        logits = model(g, features)\n\n        # Compute prediction\n        pred = logits.argmax(1)\n\n        # Compute loss\n        # Note that you should only compute the losses of the nodes in the training set.\n        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n\n        # Compute accuracy on training/validation/test\n        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n\n        # Save the best validation accuracy and the corresponding test accuracy.\n        if best_val_acc &lt; val_acc:\n            best_val_acc = val_acc\n            best_test_acc = test_acc\n\n        # Backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if e % 5 == 0:\n            print(\n                f\"In epoch {e}, loss: {loss:.3f}, val acc: {val_acc:.3f} (best {best_val_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})\"\n            )\n\n\n\nmodel = GCN(g.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\ntrain(g, model)\n\nIn epoch 0, loss: 1.946, val acc: 0.072 (best 0.072), test acc: 0.095 (best 0.095)\nIn epoch 5, loss: 1.894, val acc: 0.522 (best 0.596), test acc: 0.520 (best 0.601)\nIn epoch 10, loss: 1.813, val acc: 0.598 (best 0.598), test acc: 0.610 (best 0.610)\nIn epoch 15, loss: 1.706, val acc: 0.700 (best 0.700), test acc: 0.709 (best 0.709)\nIn epoch 20, loss: 1.574, val acc: 0.696 (best 0.708), test acc: 0.702 (best 0.713)\nIn epoch 25, loss: 1.421, val acc: 0.694 (best 0.708), test acc: 0.697 (best 0.713)\nIn epoch 30, loss: 1.253, val acc: 0.700 (best 0.708), test acc: 0.712 (best 0.713)\nIn epoch 35, loss: 1.079, val acc: 0.712 (best 0.712), test acc: 0.723 (best 0.723)\nIn epoch 40, loss: 0.909, val acc: 0.726 (best 0.726), test acc: 0.732 (best 0.731)\nIn epoch 45, loss: 0.750, val acc: 0.742 (best 0.742), test acc: 0.741 (best 0.738)\nIn epoch 50, loss: 0.610, val acc: 0.750 (best 0.750), test acc: 0.753 (best 0.753)\nIn epoch 55, loss: 0.492, val acc: 0.770 (best 0.770), test acc: 0.766 (best 0.766)\nIn epoch 60, loss: 0.395, val acc: 0.774 (best 0.776), test acc: 0.770 (best 0.769)\nIn epoch 65, loss: 0.317, val acc: 0.784 (best 0.784), test acc: 0.773 (best 0.773)\nIn epoch 70, loss: 0.257, val acc: 0.786 (best 0.786), test acc: 0.777 (best 0.776)\nIn epoch 75, loss: 0.209, val acc: 0.788 (best 0.788), test acc: 0.776 (best 0.775)\nIn epoch 80, loss: 0.172, val acc: 0.794 (best 0.794), test acc: 0.778 (best 0.778)\nIn epoch 85, loss: 0.143, val acc: 0.796 (best 0.800), test acc: 0.780 (best 0.781)\nIn epoch 90, loss: 0.121, val acc: 0.796 (best 0.800), test acc: 0.777 (best 0.781)\nIn epoch 95, loss: 0.103, val acc: 0.792 (best 0.800), test acc: 0.777 (best 0.781)\n\n\n\ng.ndata[\"feat\"][0]\n\ntensor([0., 0., 0.,  ..., 0., 0., 0.])"
  },
  {
    "objectID": "blog/2_first_post.html",
    "href": "blog/2_first_post.html",
    "title": "blog",
    "section": "",
    "text": "import os\n\nos.environ[\"DGLBACKEND\"] = \"pytorch\"\nimport dgl\nimport dgl.data\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n/Users/tu/SourceCode/dirty_data_resolver/env/lib/python3.9/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2.0 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n  warnings.warn(\n\n\n\ndataset = dgl.data.CoraGraphDataset()\nprint(f\"Number of categories: {dataset.num_classes}\")\n\nDownloading /Users/tu/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\nExtracting file to /Users/tu/.dgl/cora_v2_d697a464\nFinished data loading and preprocessing.\n  NumNodes: 2708\n  NumEdges: 10556\n  NumFeats: 1433\n  NumClasses: 7\n  NumTrainingSamples: 140\n  NumValidationSamples: 500\n  NumTestSamples: 1000\nDone saving data into cached files.\nNumber of categories: 7\n\n\n\n# A DGL Dataset object may contain one or multiple graphs. The Cora dataset used in this tutorial only consists of one single graph.\ng = dataset[0]\n\n\nprint(\"Node features\")\nprint(g.ndata.keys())\nprint(\"Edge features\")\nprint(g.edata)\n\nNode features\ndict_keys(['train_mask', 'val_mask', 'test_mask', 'label', 'feat'])\nEdge features\n{}\n\n\n\nfrom dgl.nn import GraphConv\n\n\nclass GCN(nn.Module):\n    def __init__(self, in_feats, h_feats, num_classes):\n        super(GCN, self).__init__()\n        self.conv1 = GraphConv(in_feats, h_feats)\n        self.conv2 = GraphConv(h_feats, num_classes)\n\n    def forward(self, g, in_feat):\n        h = self.conv1(g, in_feat)\n        h = F.relu(h)\n        h = self.conv2(g, h)\n        return h\n\n\n\nfrom dgl.data import DGLDataset\n\ndef train(g:DGLDataset, model: GCN):\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n    best_val_acc = 0\n    best_test_acc = 0\n\n    features = g.ndata[\"feat\"]\n    labels = g.ndata[\"label\"]\n    train_mask = g.ndata[\"train_mask\"]\n    val_mask = g.ndata[\"val_mask\"]\n    test_mask = g.ndata[\"test_mask\"]\n    for e in range(100):\n        # Forward\n        logits = model(g, features)\n\n        # Compute prediction\n        pred = logits.argmax(1)\n\n        # Compute loss\n        # Note that you should only compute the losses of the nodes in the training set.\n        loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n\n        # Compute accuracy on training/validation/test\n        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n        val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n        test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n\n        # Save the best validation accuracy and the corresponding test accuracy.\n        if best_val_acc &lt; val_acc:\n            best_val_acc = val_acc\n            best_test_acc = test_acc\n\n        # Backward\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if e % 5 == 0:\n            print(\n                f\"In epoch {e}, loss: {loss:.3f}, val acc: {val_acc:.3f} (best {best_val_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})\"\n            )\n\n\n\nmodel = GCN(g.ndata[\"feat\"].shape[1], 16, dataset.num_classes)\ntrain(g, model)\n\nIn epoch 0, loss: 1.946, val acc: 0.072 (best 0.072), test acc: 0.095 (best 0.095)\nIn epoch 5, loss: 1.894, val acc: 0.522 (best 0.596), test acc: 0.520 (best 0.601)\nIn epoch 10, loss: 1.813, val acc: 0.598 (best 0.598), test acc: 0.610 (best 0.610)\nIn epoch 15, loss: 1.706, val acc: 0.700 (best 0.700), test acc: 0.709 (best 0.709)\nIn epoch 20, loss: 1.574, val acc: 0.696 (best 0.708), test acc: 0.702 (best 0.713)\nIn epoch 25, loss: 1.421, val acc: 0.694 (best 0.708), test acc: 0.697 (best 0.713)\nIn epoch 30, loss: 1.253, val acc: 0.700 (best 0.708), test acc: 0.712 (best 0.713)\nIn epoch 35, loss: 1.079, val acc: 0.712 (best 0.712), test acc: 0.723 (best 0.723)\nIn epoch 40, loss: 0.909, val acc: 0.726 (best 0.726), test acc: 0.732 (best 0.731)\nIn epoch 45, loss: 0.750, val acc: 0.742 (best 0.742), test acc: 0.741 (best 0.738)\nIn epoch 50, loss: 0.610, val acc: 0.750 (best 0.750), test acc: 0.753 (best 0.753)\nIn epoch 55, loss: 0.492, val acc: 0.770 (best 0.770), test acc: 0.766 (best 0.766)\nIn epoch 60, loss: 0.395, val acc: 0.774 (best 0.776), test acc: 0.770 (best 0.769)\nIn epoch 65, loss: 0.317, val acc: 0.784 (best 0.784), test acc: 0.773 (best 0.773)\nIn epoch 70, loss: 0.257, val acc: 0.786 (best 0.786), test acc: 0.777 (best 0.776)\nIn epoch 75, loss: 0.209, val acc: 0.788 (best 0.788), test acc: 0.776 (best 0.775)\nIn epoch 80, loss: 0.172, val acc: 0.794 (best 0.794), test acc: 0.778 (best 0.778)\nIn epoch 85, loss: 0.143, val acc: 0.796 (best 0.800), test acc: 0.780 (best 0.781)\nIn epoch 90, loss: 0.121, val acc: 0.796 (best 0.800), test acc: 0.777 (best 0.781)\nIn epoch 95, loss: 0.103, val acc: 0.792 (best 0.800), test acc: 0.777 (best 0.781)\n\n\n\ng.ndata[\"feat\"][0]\n\ntensor([0., 0., 0.,  ..., 0., 0., 0.])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]